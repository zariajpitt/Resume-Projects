{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c98437-dccd-434d-9a2f-92afcb5ecbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_BatchDataset element_spec=(TensorSpec(shape=(None, 64, 64, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import dp_accounting\n",
    "import pandas as pd\n",
    "#import logging\n",
    "\n",
    "# Suppress TensorFlow logging (must be before importing tensorflow)\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  \n",
    "# Suppress Python logging from TensorFlow\n",
    "#logging.getLogger('tensorflow').setLevel(logging.FATAL)\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "import tensorflow_privacy\n",
    "from tensorflow_privacy import DPKerasSGDOptimizer, compute_dp_sgd_privacy_statement\n",
    " \n",
    "\n",
    "# List available physical devices\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"Available GPUs:\")\n",
    "print(gpus)\n",
    "# Mount Google Drive\n",
    "\n",
    "dataset_path = \"COVID-19_Radiography_Dataset\"\n",
    "\n",
    "# Define categories (Folders inside dataset)\n",
    "categories = [\"COVID\", \"Lung_Opacity\", \"Normal\", \"Viral Pneumonia\"]\n",
    "# Function to load and preprocess an image\n",
    "def load_image(image_path, label):\n",
    "    img = tf.io.read_file(image_path)  # Read image file\n",
    "    img = tf.image.decode_jpeg(img, channels=3)  # Decode as RGB image\n",
    "    img = tf.image.resize(img, (64, 64))  # Resize to 224x224for correct sizing in tensor flow\n",
    "    img = img / 255.0  # Normalize pixel values between 0 and 1. 224/255 = inbetween 0 and 1\n",
    "    return img, label\n",
    "    # Create empty lists to store image paths and labels\n",
    "image_paths = []\n",
    "labels = []\n",
    "k = 0\n",
    "# Loop through each category and load image paths\n",
    "i = 0\n",
    "for i, category in enumerate(categories):\n",
    "    category_path = os.path.join(dataset_path, category)\n",
    "    category_path = os.path.join(category_path, \"images\")\n",
    "    #print(category_path)\n",
    "    #print(i)\n",
    "    for img_name in os.listdir(category_path):\n",
    "        #load_image(category_path, img_name)\n",
    "        image_paths.append(os.path.join(category_path, img_name))\n",
    "        labels.append(i)\n",
    "\n",
    "\n",
    "# Convert lists to TensorFlow Dataset\n",
    "image_dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels)) #creates a dataset\n",
    "image_dataset = image_dataset.map(load_image).batch(200)#110 is ok\n",
    "print(image_dataset)\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1863c750-36c5-44c8-b083-2625fb3c6197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DP-SGD performed over 1000 examples with 2 examples per iteration, noise\n",
      "multiplier 0.3 for 1 epochs with microbatching, and no bound on number of\n",
      "examples per user.\n",
      "\n",
      "This privacy guarantee protects the release of all model checkpoints in addition\n",
      "to the final model.\n",
      "\n",
      "Example-level DP with add-or-remove-one adjacency at delta = 0.001 computed with\n",
      "RDP accounting:\n",
      "    Epsilon with each example occurring once per epoch:        45.239\n",
      "    Epsilon assuming Poisson sampling (*):                    116.412\n",
      "\n",
      "No user-level privacy guarantee is possible without a bound on the number of\n",
      "examples per user.\n",
      "\n",
      "(*) Poisson sampling is not usually done in training pipelines, but assuming\n",
      "that the data was randomly shuffled, it is believed that the actual epsilon\n",
      "should be closer to this value than the conservative assumption of an arbitrary\n",
      "data order.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#image_dataset is a 2dem array\n",
    "#simulate clients\n",
    "os.environ['TFF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "NUM_CLIENTS = 5\n",
    "client_datasets = []\n",
    "for i in range(NUM_CLIENTS):\n",
    "  client_dataset = image_dataset.shard(NUM_CLIENTS, i)  # Split dataset\n",
    "  client_datasets.append(client_dataset)#2dem array\n",
    "  #print(len(client_dataset))\n",
    "def create_model():\n",
    "    model = tf.keras.Sequential([\n",
    "    # 1st Convolutional Layer: Extracts basic features (edges, textures) #224 height and width and 3 channels for rgb color\n",
    "    tf.keras.layers.Conv2D(8, (3,3), activation='relu', input_shape=(64, 64, 3), name='convo',padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2), name='maxpool'),  # Reduces image size\n",
    "    # 2nd Convolutional Layer: Extracts more complex features\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', name='convo2'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2),name='maxpool2'),  # Reduces image size\n",
    "    tf.keras.layers.Flatten(),  # Converts 2D feature maps into 1D array\n",
    "    # Fully Connected Layer: Decides important features\n",
    "    tf.keras.layers.Dense(16, activation='relu',name= 'dense'),\n",
    "    # Output Layer: 4 classes (COVID, Lung Opacity, Normal, Viral Pneumonia)\n",
    "    tf.keras.layers.Dense(4, activation='softmax', name='dense2')\n",
    "    ])\n",
    "    #print(model.summary())\n",
    "    #model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "def model_fn():\n",
    "    keras_model = create_model()  # Create the CNN model for images\n",
    "    return tff.learning.models.from_keras_model(\n",
    "        keras_model,\n",
    "        input_spec=image_dataset.element_spec,  # Use dataset format\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),  # Match loss with model\n",
    "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]  # Track accuracy\n",
    "    )\n",
    "# Initialize Federated Averaging (FedAvg) process\n",
    "trainer = tff.learning.algorithms.build_weighted_fed_avg(model_fn, client_optimizer_fn=tff.learning.optimizers.build_sgdm(learning_rate=0.0005, momentum=0.7))\n",
    "# Initialize server state\n",
    "state = trainer.initialize()\n",
    "#Use DPKerasSGDOptimizer to add clipping and noise for differential privacy\n",
    "dpopt = DPKerasSGDOptimizer(l2_norm_clip=0.8, noise_multiplier=0.05, num_microbatches=1)\n",
    "dpstatement = compute_dp_sgd_privacy_statement(number_of_examples=1000, batch_size=2, noise_multiplier=0.3, num_epochs=1, delta=1/1000) #delta is typically 1/ num_of_examples\n",
    "print(dpstatement)\n",
    "# Simulate federated training round #This method updates weights of the model\n",
    "def client_update(client_dataset, model_weights):\n",
    "    model = create_model()\n",
    "    model.set_weights(model_weights)  # Set weights from server\n",
    "    model.compile(optimizer=dpopt, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False))  # Compile model with optimizer and loss\n",
    "    model.fit(client_dataset, epochs=3)  # Train locally for 1 epoch\n",
    "    model.summary()\n",
    "    return model.get_weights()  # Return updated weights\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56a50f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "22/22 [==============================] - 22s 909ms/step - loss: 1.4514\n",
      "Epoch 2/3\n",
      "22/22 [==============================] - 21s 994ms/step - loss: 1.3273\n",
      "Epoch 3/3\n",
      "22/22 [==============================] - 22s 1s/step - loss: 1.3122\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " convo (Conv2D)              (None, 64, 64, 8)         224       \n",
      "                                                                 \n",
      " maxpool (MaxPooling2D)      (None, 32, 32, 8)         0         \n",
      "                                                                 \n",
      " convo2 (Conv2D)             (None, 30, 30, 16)        1168      \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling2D)     (None, 15, 15, 16)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3600)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                57616     \n",
      "                                                                 \n",
      " dense2 (Dense)              (None, 4)                 68        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 59076 (230.77 KB)\n",
      "Trainable params: 59076 (230.77 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "21/21 [==============================] - 28s 1s/step - loss: 1.4245\n",
      "Epoch 2/3\n",
      "21/21 [==============================] - 18s 897ms/step - loss: 1.3103\n",
      "Epoch 3/3\n",
      "21/21 [==============================] - 18s 851ms/step - loss: 1.2624\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " convo (Conv2D)              (None, 64, 64, 8)         224       \n",
      "                                                                 \n",
      " maxpool (MaxPooling2D)      (None, 32, 32, 8)         0         \n",
      "                                                                 \n",
      " convo2 (Conv2D)             (None, 30, 30, 16)        1168      \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling2D)     (None, 15, 15, 16)        0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 3600)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                57616     \n",
      "                                                                 \n",
      " dense2 (Dense)              (None, 4)                 68        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 59076 (230.77 KB)\n",
      "Trainable params: 59076 (230.77 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "21/21 [==============================] - 21s 912ms/step - loss: 1.4387\n",
      "Epoch 2/3\n",
      "21/21 [==============================] - 17s 841ms/step - loss: 1.3040\n",
      "Epoch 3/3\n",
      "21/21 [==============================] - 18s 839ms/step - loss: 1.2706\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " convo (Conv2D)              (None, 64, 64, 8)         224       \n",
      "                                                                 \n",
      " maxpool (MaxPooling2D)      (None, 32, 32, 8)         0         \n",
      "                                                                 \n",
      " convo2 (Conv2D)             (None, 30, 30, 16)        1168      \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling2D)     (None, 15, 15, 16)        0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 3600)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                57616     \n",
      "                                                                 \n",
      " dense2 (Dense)              (None, 4)                 68        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 59076 (230.77 KB)\n",
      "Trainable params: 59076 (230.77 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "21/21 [==============================] - 25s 1s/step - loss: 1.4140\n",
      "Epoch 2/3\n",
      "21/21 [==============================] - 22s 1s/step - loss: 1.2349\n",
      "Epoch 3/3\n",
      "21/21 [==============================] - 22s 1s/step - loss: 1.1957\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " convo (Conv2D)              (None, 64, 64, 8)         224       \n",
      "                                                                 \n",
      " maxpool (MaxPooling2D)      (None, 32, 32, 8)         0         \n",
      "                                                                 \n",
      " convo2 (Conv2D)             (None, 30, 30, 16)        1168      \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling2D)     (None, 15, 15, 16)        0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 3600)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                57616     \n",
      "                                                                 \n",
      " dense2 (Dense)              (None, 4)                 68        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 59076 (230.77 KB)\n",
      "Trainable params: 59076 (230.77 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "21/21 [==============================] - 21s 884ms/step - loss: 1.4289\n",
      "Epoch 2/3\n",
      "21/21 [==============================] - 18s 864ms/step - loss: 1.3031\n",
      "Epoch 3/3\n",
      "21/21 [==============================] - 18s 838ms/step - loss: 1.2668\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " convo (Conv2D)              (None, 64, 64, 8)         224       \n",
      "                                                                 \n",
      " maxpool (MaxPooling2D)      (None, 32, 32, 8)         0         \n",
      "                                                                 \n",
      " convo2 (Conv2D)             (None, 30, 30, 16)        1168      \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling2D)     (None, 15, 15, 16)        0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 3600)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                57616     \n",
      "                                                                 \n",
      " dense2 (Dense)              (None, 4)                 68        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 59076 (230.77 KB)\n",
      "Trainable params: 59076 (230.77 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "os.environ['TFF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "client_weights = []\n",
    "for client in client_datasets:\n",
    "  new_weights = client_update(client, state.global_model_weights.trainable)\n",
    "  client_weights.append(new_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fca9c9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<_ShardDataset element_spec=(TensorSpec(shape=(None, 64, 64, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>, <_ShardDataset element_spec=(TensorSpec(shape=(None, 64, 64, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>, <_ShardDataset element_spec=(TensorSpec(shape=(None, 64, 64, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>, <_ShardDataset element_spec=(TensorSpec(shape=(None, 64, 64, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>, <_ShardDataset element_spec=(TensorSpec(shape=(None, 64, 64, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>]\n",
      "Round 1\n",
      "Round 1 metrics: OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.13630995), ('loss', 1.5503649), ('num_examples', 21165), ('num_batches', 106)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
      "Round 2\n",
      "Round 2 metrics: OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.0919915), ('loss', 1.4307369), ('num_examples', 21165), ('num_batches', 106)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
      "Round 3\n",
      "Round 3 metrics: OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.09496811), ('loss', 1.4110368), ('num_examples', 21165), ('num_batches', 106)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
      "Federated learning round complete!\n"
     ]
    }
   ],
   "source": [
    "#[arr1,arr2,arr3]axis 1 -> # client weights array [arr1,arr2,arr3]\n",
    "#[#   ,#   ,#   ]          #print(len(client_weights[0])) output = 8 y\n",
    "#[#   ,#   ,#   ]          #print(len(client_weights[0][0])) output = 3 x\n",
    "#[#   ,#   ,#   ]\n",
    "#[#   ,#   ,#   ]\n",
    "#axis0^\n",
    "#1.get average weight of first column, 2nd and third. These are the averages ofthe layers.\n",
    "os.environ['TFF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "averages = []\n",
    "layer_weights = []\n",
    "# Each client_weights is a list of arrays, where each array represents a layer's weights\n",
    "for layer_index in range(len(client_weights[0])):  #[arr1,arr2,arr3] # take length of client_weights[0] to beacause all arrays should be equal in size #8\n",
    "    #layer_index is what row you are on\n",
    "    layer_weights = []  # Collect this layer’s weights from all clients\n",
    "\n",
    "    # Collect the same layer weights from each client(column in the array)\n",
    "    for client in client_weights:\n",
    "        layer_weights.append(client[layer_index])\n",
    "\n",
    "    # Average the collected weights for this layer\n",
    "    layer_average = np.mean(layer_weights, axis=0)\n",
    "    averages.append(layer_average)  # Store averaged layer weights\n",
    "\n",
    "    # Debugging: Print info about this layer’s weights\n",
    "    #print(f\"Collected weights shape: {[w.shape for w in layer_weights]}\")\n",
    "    #print(f\"Averaged weights shape: {layer_average.shape}\\n\")\n",
    "\n",
    "federated_data = [client_datasets[i] for i in range(NUM_CLIENTS)]\n",
    "print(federated_data) \n",
    "# Update global model weights with the averaged weights\n",
    "for round_num in range(1, 4):\n",
    "    print(f\"Round {round_num}\")\n",
    "    state, metrics = trainer.next(state,federated_data)\n",
    "    print(f\"Round {round_num} metrics:\", metrics)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Federated learning round complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
